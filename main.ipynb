{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev. set missing data in 4804 samples out of 6863\n",
      "Test set missing data in 0 samples out of 1716\n",
      "Fitting a model on the dataset from where samples with missing data have been dropped\n",
      "Learning rate set to 0.072039\n",
      "0:\ttest: 0.6647039\tbest: 0.6647039 (0)\ttotal: 54.6ms\tremaining: 10.9s\n",
      "20:\ttest: 0.7180162\tbest: 0.7190403 (17)\ttotal: 119ms\tremaining: 1.02s\n",
      "40:\ttest: 0.7148953\tbest: 0.7223319 (33)\ttotal: 211ms\tremaining: 817ms\n",
      "60:\ttest: 0.7145783\tbest: 0.7223319 (33)\ttotal: 281ms\tremaining: 641ms\n",
      "80:\ttest: 0.7057762\tbest: 0.7223319 (33)\ttotal: 347ms\tremaining: 510ms\n",
      "100:\ttest: 0.7063614\tbest: 0.7223319 (33)\ttotal: 402ms\tremaining: 394ms\n",
      "120:\ttest: 0.7011435\tbest: 0.7223319 (33)\ttotal: 470ms\tremaining: 307ms\n",
      "140:\ttest: 0.7040207\tbest: 0.7223319 (33)\ttotal: 532ms\tremaining: 223ms\n",
      "160:\ttest: 0.6968522\tbest: 0.7223319 (33)\ttotal: 595ms\tremaining: 144ms\n",
      "180:\ttest: 0.6947066\tbest: 0.7223319 (33)\ttotal: 658ms\tremaining: 69.1ms\n",
      "199:\ttest: 0.6919269\tbest: 0.7223319 (33)\ttotal: 719ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7223319435\n",
      "bestIteration = 33\n",
      "\n",
      "Shrink model to first 34 iterations.\n",
      "Train ROC AUC: 0.8388361111938349\n",
      "Val ROC AUC: 0.7223319435301002\n",
      "Test ROC AUC: 0.7228808911016413\n",
      "Performing grid-search for hyper-parameters optimization, without samples with missing data\n",
      "\n",
      "bestTest = 0.6517794473\n",
      "bestIteration = 21\n",
      "\n",
      "0:\tloss: 0.6517794\tbest: 0.6517794 (0)\ttotal: 320ms\tremaining: 15.3s\n",
      "\n",
      "bestTest = 0.6769698703\n",
      "bestIteration = 186\n",
      "\n",
      "1:\tloss: 0.6769699\tbest: 0.6769699 (1)\ttotal: 639ms\tremaining: 15s\n",
      "\n",
      "bestTest = 0.6880183014\n",
      "bestIteration = 155\n",
      "\n",
      "2:\tloss: 0.6880183\tbest: 0.6880183 (2)\ttotal: 957ms\tremaining: 14.7s\n",
      "\n",
      "bestTest = 0.6882002756\n",
      "bestIteration = 198\n",
      "\n",
      "3:\tloss: 0.6882003\tbest: 0.6882003 (3)\ttotal: 1.26s\tremaining: 14.2s\n",
      "\n",
      "bestTest = 0.6836509216\n",
      "bestIteration = 194\n",
      "\n",
      "4:\tloss: 0.6836509\tbest: 0.6882003 (3)\ttotal: 1.57s\tremaining: 13.8s\n",
      "\n",
      "bestTest = 0.6853926742\n",
      "bestIteration = 199\n",
      "\n",
      "5:\tloss: 0.6853927\tbest: 0.6882003 (3)\ttotal: 1.88s\tremaining: 13.5s\n",
      "\n",
      "bestTest = 0.6817271947\n",
      "bestIteration = 71\n",
      "\n",
      "6:\tloss: 0.6817272\tbest: 0.6882003 (3)\ttotal: 2.18s\tremaining: 13.1s\n",
      "\n",
      "bestTest = 0.6642316791\n",
      "bestIteration = 199\n",
      "\n",
      "7:\tloss: 0.6642317\tbest: 0.6882003 (3)\ttotal: 2.44s\tremaining: 12.5s\n",
      "\n",
      "bestTest = 0.6841708477\n",
      "bestIteration = 198\n",
      "\n",
      "8:\tloss: 0.6841708\tbest: 0.6882003 (3)\ttotal: 2.68s\tremaining: 11.9s\n",
      "\n",
      "bestTest = 0.6943094081\n",
      "bestIteration = 195\n",
      "\n",
      "9:\tloss: 0.6943094\tbest: 0.6943094 (9)\ttotal: 2.92s\tremaining: 11.4s\n",
      "\n",
      "bestTest = 0.685964593\n",
      "bestIteration = 154\n",
      "\n",
      "10:\tloss: 0.6859646\tbest: 0.6943094 (9)\ttotal: 3.17s\tremaining: 10.9s\n",
      "\n",
      "bestTest = 0.6848467518\n",
      "bestIteration = 165\n",
      "\n",
      "11:\tloss: 0.6848468\tbest: 0.6943094 (9)\ttotal: 3.41s\tremaining: 10.5s\n",
      "\n",
      "bestTest = 0.6852366964\n",
      "bestIteration = 77\n",
      "\n",
      "12:\tloss: 0.6852367\tbest: 0.6943094 (9)\ttotal: 3.66s\tremaining: 10.1s\n",
      "\n",
      "bestTest = 0.6819351652\n",
      "bestIteration = 87\n",
      "\n",
      "13:\tloss: 0.6819352\tbest: 0.6943094 (9)\ttotal: 3.91s\tremaining: 9.77s\n",
      "\n",
      "bestTest = 0.6694829334\n",
      "bestIteration = 197\n",
      "\n",
      "14:\tloss: 0.6694829\tbest: 0.6943094 (9)\ttotal: 4.2s\tremaining: 9.52s\n",
      "\n",
      "bestTest = 0.695063301\n",
      "bestIteration = 167\n",
      "\n",
      "15:\tloss: 0.6950633\tbest: 0.6950633 (15)\ttotal: 4.49s\tremaining: 9.25s\n",
      "\n",
      "bestTest = 0.6926456443\n",
      "bestIteration = 195\n",
      "\n",
      "16:\tloss: 0.6926456\tbest: 0.6950633 (15)\ttotal: 4.83s\tremaining: 9.1s\n",
      "\n",
      "bestTest = 0.6858866041\n",
      "bestIteration = 179\n",
      "\n",
      "17:\tloss: 0.6858866\tbest: 0.6950633 (15)\ttotal: 5.2s\tremaining: 8.96s\n",
      "\n",
      "bestTest = 0.6917617698\n",
      "bestIteration = 189\n",
      "\n",
      "18:\tloss: 0.6917618\tbest: 0.6950633 (15)\ttotal: 6.1s\tremaining: 9.63s\n",
      "\n",
      "bestTest = 0.6857826189\n",
      "bestIteration = 167\n",
      "\n",
      "19:\tloss: 0.6857826\tbest: 0.6950633 (15)\ttotal: 6.63s\tremaining: 9.61s\n",
      "\n",
      "bestTest = 0.6966750721\n",
      "bestIteration = 79\n",
      "\n",
      "20:\tloss: 0.6966751\tbest: 0.6966751 (20)\ttotal: 6.92s\tremaining: 9.23s\n",
      "\n",
      "bestTest = 0.6750591416\n",
      "bestIteration = 2\n",
      "\n",
      "21:\tloss: 0.6750591\tbest: 0.6966751 (20)\ttotal: 7.28s\tremaining: 8.93s\n",
      "\n",
      "bestTest = 0.6916577846\n",
      "bestIteration = 198\n",
      "\n",
      "22:\tloss: 0.6916578\tbest: 0.6966751 (20)\ttotal: 7.71s\tremaining: 8.72s\n",
      "\n",
      "bestTest = 0.6959211792\n",
      "bestIteration = 146\n",
      "\n",
      "23:\tloss: 0.6959212\tbest: 0.6966751 (20)\ttotal: 8.3s\tremaining: 8.65s\n",
      "\n",
      "bestTest = 0.6769958666\n",
      "bestIteration = 2\n",
      "\n",
      "24:\tloss: 0.6769959\tbest: 0.6966751 (20)\ttotal: 8.65s\tremaining: 8.3s\n",
      "\n",
      "bestTest = 0.6903059766\n",
      "bestIteration = 122\n",
      "\n",
      "25:\tloss: 0.6903060\tbest: 0.6966751 (20)\ttotal: 9.28s\tremaining: 8.21s\n",
      "\n",
      "bestTest = 0.6951672862\n",
      "bestIteration = 162\n",
      "\n",
      "26:\tloss: 0.6951673\tbest: 0.6966751 (20)\ttotal: 9.84s\tremaining: 8.02s\n",
      "\n",
      "bestTest = 0.6994306808\n",
      "bestIteration = 23\n",
      "\n",
      "27:\tloss: 0.6994307\tbest: 0.6994307 (27)\ttotal: 10.4s\tremaining: 7.78s\n",
      "\n",
      "bestTest = 0.6725764941\n",
      "bestIteration = 199\n",
      "\n",
      "28:\tloss: 0.6725765\tbest: 0.6994307 (27)\ttotal: 10.8s\tremaining: 7.43s\n",
      "\n",
      "bestTest = 0.6925936517\n",
      "bestIteration = 131\n",
      "\n",
      "29:\tloss: 0.6925937\tbest: 0.6994307 (27)\ttotal: 11.2s\tremaining: 7.06s\n",
      "\n",
      "bestTest = 0.6930875816\n",
      "bestIteration = 185\n",
      "\n",
      "30:\tloss: 0.6930876\tbest: 0.6994307 (27)\ttotal: 11.5s\tremaining: 6.7s\n",
      "\n",
      "bestTest = 0.6952192789\n",
      "bestIteration = 170\n",
      "\n",
      "31:\tloss: 0.6952193\tbest: 0.6994307 (27)\ttotal: 12.4s\tremaining: 6.57s\n",
      "\n",
      "bestTest = 0.6865105155\n",
      "bestIteration = 103\n",
      "\n",
      "32:\tloss: 0.6865105\tbest: 0.6994307 (27)\ttotal: 12.9s\tremaining: 6.27s\n",
      "\n",
      "bestTest = 0.7001325812\n",
      "bestIteration = 133\n",
      "\n",
      "33:\tloss: 0.7001326\tbest: 0.7001326 (33)\ttotal: 13.4s\tremaining: 5.92s\n",
      "\n",
      "bestTest = 0.682507084\n",
      "bestIteration = 169\n",
      "\n",
      "34:\tloss: 0.6825071\tbest: 0.7001326 (33)\ttotal: 13.8s\tremaining: 5.53s\n",
      "\n",
      "bestTest = 0.6814672317\n",
      "bestIteration = 186\n",
      "\n",
      "35:\tloss: 0.6814672\tbest: 0.7001326 (33)\ttotal: 14.3s\tremaining: 5.17s\n",
      "\n",
      "bestTest = 0.6929056074\n",
      "bestIteration = 102\n",
      "\n",
      "36:\tloss: 0.6929056\tbest: 0.7001326 (33)\ttotal: 14.9s\tremaining: 4.83s\n",
      "\n",
      "bestTest = 0.7032261419\n",
      "bestIteration = 179\n",
      "\n",
      "37:\tloss: 0.7032261\tbest: 0.7032261 (37)\ttotal: 15.4s\tremaining: 4.47s\n",
      "\n",
      "bestTest = 0.6949853121\n",
      "bestIteration = 93\n",
      "\n",
      "38:\tloss: 0.6949853\tbest: 0.7032261 (37)\ttotal: 16.1s\tremaining: 4.12s\n",
      "\n",
      "bestTest = 0.7082954221\n",
      "bestIteration = 150\n",
      "\n",
      "39:\tloss: 0.7082954\tbest: 0.7082954 (39)\ttotal: 16.6s\tremaining: 3.73s\n",
      "\n",
      "bestTest = 0.6878623236\n",
      "bestIteration = 185\n",
      "\n",
      "40:\tloss: 0.6878623\tbest: 0.7082954 (39)\ttotal: 17.3s\tremaining: 3.38s\n",
      "\n",
      "bestTest = 0.6925676554\n",
      "bestIteration = 54\n",
      "\n",
      "41:\tloss: 0.6925677\tbest: 0.7082954 (39)\ttotal: 18.2s\tremaining: 3.03s\n",
      "\n",
      "bestTest = 0.6815192243\n",
      "bestIteration = 191\n",
      "\n",
      "42:\tloss: 0.6815192\tbest: 0.7082954 (39)\ttotal: 19.1s\tremaining: 2.66s\n",
      "\n",
      "bestTest = 0.6979228949\n",
      "bestIteration = 197\n",
      "\n",
      "43:\tloss: 0.6979229\tbest: 0.7082954 (39)\ttotal: 20.4s\tremaining: 2.32s\n",
      "\n",
      "bestTest = 0.6906439286\n",
      "bestIteration = 187\n",
      "\n",
      "44:\tloss: 0.6906439\tbest: 0.7082954 (39)\ttotal: 21.4s\tremaining: 1.9s\n",
      "\n",
      "bestTest = 0.6955052383\n",
      "bestIteration = 177\n",
      "\n",
      "45:\tloss: 0.6955052\tbest: 0.7082954 (39)\ttotal: 22.5s\tremaining: 1.47s\n",
      "\n",
      "bestTest = 0.6858866041\n",
      "bestIteration = 51\n",
      "\n",
      "46:\tloss: 0.6858866\tbest: 0.7082954 (39)\ttotal: 23.5s\tremaining: 999ms\n",
      "\n",
      "bestTest = 0.7017703486\n",
      "bestIteration = 25\n",
      "\n",
      "47:\tloss: 0.7017703\tbest: 0.7082954 (39)\ttotal: 24.4s\tremaining: 508ms\n",
      "\n",
      "bestTest = 0.6728624535\n",
      "bestIteration = 170\n",
      "\n",
      "48:\tloss: 0.6728625\tbest: 0.7082954 (39)\ttotal: 25.1s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Best params {'depth': 7, 'learning_rate': 0.08} obtained at iteration 63 with logloss 0.5902095788007137\n",
      "Dev ROC AUC on best model after grid-search: 0.9971186987806274\n",
      "Test ROC AUC on best model after grid-search: 0.7314290536264293\n",
      "Performing grid-search for hyper-parameters optimization, with missing data replaced with a mean imputer\n",
      "\n",
      "bestTest = 0.4395853749\n",
      "bestIteration = 199\n",
      "\n",
      "0:\tloss: 0.4395854\tbest: 0.4395854 (0)\ttotal: 414ms\tremaining: 19.9s\n",
      "\n",
      "bestTest = 0.4221555949\n",
      "bestIteration = 197\n",
      "\n",
      "1:\tloss: 0.4221556\tbest: 0.4221556 (1)\ttotal: 823ms\tremaining: 19.3s\n",
      "\n",
      "bestTest = 0.4213731845\n",
      "bestIteration = 191\n",
      "\n",
      "2:\tloss: 0.4213732\tbest: 0.4213732 (2)\ttotal: 1.23s\tremaining: 18.8s\n",
      "\n",
      "bestTest = 0.4195817014\n",
      "bestIteration = 199\n",
      "\n",
      "3:\tloss: 0.4195817\tbest: 0.4195817 (3)\ttotal: 1.67s\tremaining: 18.8s\n",
      "\n",
      "bestTest = 0.420164488\n",
      "bestIteration = 174\n",
      "\n",
      "4:\tloss: 0.4201645\tbest: 0.4195817 (3)\ttotal: 2.09s\tremaining: 18.4s\n",
      "\n",
      "bestTest = 0.4183169819\n",
      "bestIteration = 199\n",
      "\n",
      "5:\tloss: 0.4183170\tbest: 0.4183170 (5)\ttotal: 2.51s\tremaining: 18s\n",
      "\n",
      "bestTest = 0.420486526\n",
      "bestIteration = 136\n",
      "\n",
      "6:\tloss: 0.4204865\tbest: 0.4183170 (5)\ttotal: 2.94s\tremaining: 17.6s\n",
      "\n",
      "bestTest = 0.4354976625\n",
      "bestIteration = 199\n",
      "\n",
      "7:\tloss: 0.4354977\tbest: 0.4183170 (5)\ttotal: 3.43s\tremaining: 17.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4192191388\n",
      "bestIteration = 199\n",
      "\n",
      "8:\tloss: 0.4192191\tbest: 0.4183170 (5)\ttotal: 3.92s\tremaining: 17.4s\n",
      "\n",
      "bestTest = 0.4189362827\n",
      "bestIteration = 191\n",
      "\n",
      "9:\tloss: 0.4189363\tbest: 0.4183170 (5)\ttotal: 4.39s\tremaining: 17.1s\n",
      "\n",
      "bestTest = 0.4192582282\n",
      "bestIteration = 138\n",
      "\n",
      "10:\tloss: 0.4192582\tbest: 0.4183170 (5)\ttotal: 4.87s\tremaining: 16.8s\n",
      "\n",
      "bestTest = 0.4196626446\n",
      "bestIteration = 186\n",
      "\n",
      "11:\tloss: 0.4196626\tbest: 0.4183170 (5)\ttotal: 5.35s\tremaining: 16.5s\n",
      "\n",
      "bestTest = 0.4200144596\n",
      "bestIteration = 123\n",
      "\n",
      "12:\tloss: 0.4200145\tbest: 0.4183170 (5)\ttotal: 5.83s\tremaining: 16.2s\n",
      "\n",
      "bestTest = 0.420013091\n",
      "bestIteration = 86\n",
      "\n",
      "13:\tloss: 0.4200131\tbest: 0.4183170 (5)\ttotal: 6.33s\tremaining: 15.8s\n",
      "\n",
      "bestTest = 0.4322349709\n",
      "bestIteration = 199\n",
      "\n",
      "14:\tloss: 0.4322350\tbest: 0.4183170 (5)\ttotal: 6.86s\tremaining: 15.5s\n",
      "\n",
      "bestTest = 0.4213532978\n",
      "bestIteration = 185\n",
      "\n",
      "15:\tloss: 0.4213533\tbest: 0.4183170 (5)\ttotal: 7.4s\tremaining: 15.3s\n",
      "\n",
      "bestTest = 0.4174866477\n",
      "bestIteration = 199\n",
      "\n",
      "16:\tloss: 0.4174866\tbest: 0.4174866 (16)\ttotal: 7.94s\tremaining: 15s\n",
      "\n",
      "bestTest = 0.4159463306\n",
      "bestIteration = 198\n",
      "\n",
      "17:\tloss: 0.4159463\tbest: 0.4159463 (17)\ttotal: 8.5s\tremaining: 14.6s\n",
      "\n",
      "bestTest = 0.4169562664\n",
      "bestIteration = 142\n",
      "\n",
      "18:\tloss: 0.4169563\tbest: 0.4159463 (17)\ttotal: 9.04s\tremaining: 14.3s\n",
      "\n",
      "bestTest = 0.4219211941\n",
      "bestIteration = 75\n",
      "\n",
      "19:\tloss: 0.4219212\tbest: 0.4159463 (17)\ttotal: 9.61s\tremaining: 13.9s\n",
      "\n",
      "bestTest = 0.416825246\n",
      "bestIteration = 74\n",
      "\n",
      "20:\tloss: 0.4168252\tbest: 0.4159463 (17)\ttotal: 10.2s\tremaining: 13.5s\n",
      "\n",
      "bestTest = 0.4305821022\n",
      "bestIteration = 199\n",
      "\n",
      "21:\tloss: 0.4305821\tbest: 0.4159463 (17)\ttotal: 10.8s\tremaining: 13.3s\n",
      "\n",
      "bestTest = 0.4217828486\n",
      "bestIteration = 168\n",
      "\n",
      "22:\tloss: 0.4217828\tbest: 0.4159463 (17)\ttotal: 11.5s\tremaining: 13s\n",
      "\n",
      "bestTest = 0.4191103689\n",
      "bestIteration = 195\n",
      "\n",
      "23:\tloss: 0.4191104\tbest: 0.4159463 (17)\ttotal: 12.1s\tremaining: 12.6s\n",
      "\n",
      "bestTest = 0.4202599171\n",
      "bestIteration = 159\n",
      "\n",
      "24:\tloss: 0.4202599\tbest: 0.4159463 (17)\ttotal: 12.7s\tremaining: 12.2s\n",
      "\n",
      "bestTest = 0.4186702831\n",
      "bestIteration = 164\n",
      "\n",
      "25:\tloss: 0.4186703\tbest: 0.4159463 (17)\ttotal: 13.3s\tremaining: 11.8s\n",
      "\n",
      "bestTest = 0.4193373869\n",
      "bestIteration = 156\n",
      "\n",
      "26:\tloss: 0.4193374\tbest: 0.4159463 (17)\ttotal: 14s\tremaining: 11.4s\n",
      "\n",
      "bestTest = 0.4225308999\n",
      "bestIteration = 51\n",
      "\n",
      "27:\tloss: 0.4225309\tbest: 0.4159463 (17)\ttotal: 14.6s\tremaining: 10.9s\n",
      "\n",
      "bestTest = 0.4287425585\n",
      "bestIteration = 199\n",
      "\n",
      "28:\tloss: 0.4287426\tbest: 0.4159463 (17)\ttotal: 15.6s\tremaining: 10.7s\n",
      "\n",
      "bestTest = 0.4203647412\n",
      "bestIteration = 128\n",
      "\n",
      "29:\tloss: 0.4203647\tbest: 0.4159463 (17)\ttotal: 16.3s\tremaining: 10.3s\n",
      "\n",
      "bestTest = 0.4204354885\n",
      "bestIteration = 182\n",
      "\n",
      "30:\tloss: 0.4204355\tbest: 0.4159463 (17)\ttotal: 17.1s\tremaining: 9.91s\n",
      "\n",
      "bestTest = 0.4195257568\n",
      "bestIteration = 163\n",
      "\n",
      "31:\tloss: 0.4195258\tbest: 0.4159463 (17)\ttotal: 17.9s\tremaining: 9.49s\n",
      "\n",
      "bestTest = 0.4228497026\n",
      "bestIteration = 153\n",
      "\n",
      "32:\tloss: 0.4228497\tbest: 0.4159463 (17)\ttotal: 18.9s\tremaining: 9.18s\n",
      "\n",
      "bestTest = 0.4179230303\n",
      "bestIteration = 123\n",
      "\n",
      "33:\tloss: 0.4179230\tbest: 0.4159463 (17)\ttotal: 19.8s\tremaining: 8.72s\n",
      "\n",
      "bestTest = 0.4221773772\n",
      "bestIteration = 72\n",
      "\n",
      "34:\tloss: 0.4221774\tbest: 0.4159463 (17)\ttotal: 20.6s\tremaining: 8.24s\n",
      "\n",
      "bestTest = 0.4280229934\n",
      "bestIteration = 199\n",
      "\n",
      "35:\tloss: 0.4280230\tbest: 0.4159463 (17)\ttotal: 21.4s\tremaining: 7.73s\n",
      "\n",
      "bestTest = 0.4187834383\n",
      "bestIteration = 172\n",
      "\n",
      "36:\tloss: 0.4187834\tbest: 0.4159463 (17)\ttotal: 22.4s\tremaining: 7.27s\n",
      "\n",
      "bestTest = 0.4187763995\n",
      "bestIteration = 91\n",
      "\n",
      "37:\tloss: 0.4187764\tbest: 0.4159463 (17)\ttotal: 23.3s\tremaining: 6.75s\n",
      "\n",
      "bestTest = 0.4209866114\n",
      "bestIteration = 60\n",
      "\n",
      "38:\tloss: 0.4209866\tbest: 0.4159463 (17)\ttotal: 24.5s\tremaining: 6.27s\n",
      "\n",
      "bestTest = 0.4212558556\n",
      "bestIteration = 113\n",
      "\n",
      "39:\tloss: 0.4212559\tbest: 0.4159463 (17)\ttotal: 25.4s\tremaining: 5.72s\n",
      "\n",
      "bestTest = 0.423504759\n",
      "bestIteration = 36\n",
      "\n",
      "40:\tloss: 0.4235048\tbest: 0.4159463 (17)\ttotal: 26.7s\tremaining: 5.2s\n",
      "\n",
      "bestTest = 0.4204005914\n",
      "bestIteration = 24\n",
      "\n",
      "41:\tloss: 0.4204006\tbest: 0.4159463 (17)\ttotal: 27.8s\tremaining: 4.63s\n",
      "\n",
      "bestTest = 0.4270244304\n",
      "bestIteration = 199\n",
      "\n",
      "42:\tloss: 0.4270244\tbest: 0.4159463 (17)\ttotal: 29.2s\tremaining: 4.07s\n",
      "\n",
      "bestTest = 0.4208446835\n",
      "bestIteration = 195\n",
      "\n",
      "43:\tloss: 0.4208447\tbest: 0.4159463 (17)\ttotal: 30.3s\tremaining: 3.45s\n",
      "\n",
      "bestTest = 0.4230754846\n",
      "bestIteration = 76\n",
      "\n",
      "44:\tloss: 0.4230755\tbest: 0.4159463 (17)\ttotal: 31.5s\tremaining: 2.8s\n",
      "\n",
      "bestTest = 0.4225376258\n",
      "bestIteration = 63\n",
      "\n",
      "45:\tloss: 0.4225376\tbest: 0.4159463 (17)\ttotal: 32.7s\tremaining: 2.13s\n",
      "\n",
      "bestTest = 0.4241720277\n",
      "bestIteration = 63\n",
      "\n",
      "46:\tloss: 0.4241720\tbest: 0.4159463 (17)\ttotal: 33.9s\tremaining: 1.44s\n",
      "\n",
      "bestTest = 0.4236480163\n",
      "bestIteration = 58\n",
      "\n",
      "47:\tloss: 0.4236480\tbest: 0.4159463 (17)\ttotal: 35s\tremaining: 730ms\n",
      "\n",
      "bestTest = 0.4288661532\n",
      "bestIteration = 13\n",
      "\n",
      "48:\tloss: 0.4288662\tbest: 0.4159463 (17)\ttotal: 36.2s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Best params {'depth': 4, 'learning_rate': 0.07} obtained at iteration 145 with logloss 0.40889205947310253\n",
      "Dev ROC AUC on best model after grid-search: 0.8304966608493832\n",
      "Test ROC AUC on best model after grid-search: 0.7314290536264293\n",
      "Performing grid-search for hyper-parameters optimization, with missing data replaced with an iterative imputer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Early stopping criterion not reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4392380289\n",
      "bestIteration = 199\n",
      "\n",
      "0:\tloss: 0.4392380\tbest: 0.4392380 (0)\ttotal: 449ms\tremaining: 21.6s\n",
      "\n",
      "bestTest = 0.422682308\n",
      "bestIteration = 197\n",
      "\n",
      "1:\tloss: 0.4226823\tbest: 0.4226823 (1)\ttotal: 954ms\tremaining: 22.4s\n",
      "\n",
      "bestTest = 0.4224265843\n",
      "bestIteration = 199\n",
      "\n",
      "2:\tloss: 0.4224266\tbest: 0.4224266 (2)\ttotal: 1.52s\tremaining: 23.4s\n",
      "\n",
      "bestTest = 0.4209614742\n",
      "bestIteration = 198\n",
      "\n",
      "3:\tloss: 0.4209615\tbest: 0.4209615 (3)\ttotal: 2.09s\tremaining: 23.5s\n",
      "\n",
      "bestTest = 0.4214819279\n",
      "bestIteration = 193\n",
      "\n",
      "4:\tloss: 0.4214819\tbest: 0.4209615 (3)\ttotal: 2.7s\tremaining: 23.8s\n",
      "\n",
      "bestTest = 0.4186855926\n",
      "bestIteration = 199\n",
      "\n",
      "5:\tloss: 0.4186856\tbest: 0.4186856 (5)\ttotal: 3.25s\tremaining: 23.3s\n",
      "\n",
      "bestTest = 0.4198147148\n",
      "bestIteration = 126\n",
      "\n",
      "6:\tloss: 0.4198147\tbest: 0.4186856 (5)\ttotal: 3.79s\tremaining: 22.7s\n",
      "\n",
      "bestTest = 0.4347846432\n",
      "bestIteration = 199\n",
      "\n",
      "7:\tloss: 0.4347846\tbest: 0.4186856 (5)\ttotal: 4.3s\tremaining: 22.1s\n",
      "\n",
      "bestTest = 0.4192538067\n",
      "bestIteration = 195\n",
      "\n",
      "8:\tloss: 0.4192538\tbest: 0.4186856 (5)\ttotal: 4.78s\tremaining: 21.3s\n",
      "\n",
      "bestTest = 0.4198238399\n",
      "bestIteration = 199\n",
      "\n",
      "9:\tloss: 0.4198238\tbest: 0.4186856 (5)\ttotal: 5.28s\tremaining: 20.6s\n",
      "\n",
      "bestTest = 0.4185330678\n",
      "bestIteration = 184\n",
      "\n",
      "10:\tloss: 0.4185331\tbest: 0.4185331 (10)\ttotal: 5.77s\tremaining: 19.9s\n",
      "\n",
      "bestTest = 0.4191242326\n",
      "bestIteration = 199\n",
      "\n",
      "11:\tloss: 0.4191242\tbest: 0.4185331 (10)\ttotal: 6.34s\tremaining: 19.6s\n",
      "\n",
      "bestTest = 0.4163287269\n",
      "bestIteration = 182\n",
      "\n",
      "12:\tloss: 0.4163287\tbest: 0.4163287 (12)\ttotal: 7.09s\tremaining: 19.6s\n",
      "\n",
      "bestTest = 0.418970041\n",
      "bestIteration = 122\n",
      "\n",
      "13:\tloss: 0.4189700\tbest: 0.4163287 (12)\ttotal: 7.65s\tremaining: 19.1s\n",
      "\n",
      "bestTest = 0.4320097627\n",
      "bestIteration = 199\n",
      "\n",
      "14:\tloss: 0.4320098\tbest: 0.4163287 (12)\ttotal: 8.2s\tremaining: 18.6s\n",
      "\n",
      "bestTest = 0.4197845467\n",
      "bestIteration = 186\n",
      "\n",
      "15:\tloss: 0.4197845\tbest: 0.4163287 (12)\ttotal: 8.79s\tremaining: 18.1s\n",
      "\n",
      "bestTest = 0.4186212695\n",
      "bestIteration = 185\n",
      "\n",
      "16:\tloss: 0.4186213\tbest: 0.4163287 (12)\ttotal: 9.38s\tremaining: 17.6s\n",
      "\n",
      "bestTest = 0.4170496442\n",
      "bestIteration = 199\n",
      "\n",
      "17:\tloss: 0.4170496\tbest: 0.4163287 (12)\ttotal: 9.96s\tremaining: 17.1s\n",
      "\n",
      "bestTest = 0.419293341\n",
      "bestIteration = 158\n",
      "\n",
      "18:\tloss: 0.4192933\tbest: 0.4163287 (12)\ttotal: 10.5s\tremaining: 16.6s\n",
      "\n",
      "bestTest = 0.4210275797\n",
      "bestIteration = 120\n",
      "\n",
      "19:\tloss: 0.4210276\tbest: 0.4163287 (12)\ttotal: 11.2s\tremaining: 16.3s\n",
      "\n",
      "bestTest = 0.4184170836\n",
      "bestIteration = 62\n",
      "\n",
      "20:\tloss: 0.4184171\tbest: 0.4163287 (12)\ttotal: 12.2s\tremaining: 16.3s\n",
      "\n",
      "bestTest = 0.4305660728\n",
      "bestIteration = 199\n",
      "\n",
      "21:\tloss: 0.4305661\tbest: 0.4163287 (12)\ttotal: 12.8s\tremaining: 15.7s\n",
      "\n",
      "bestTest = 0.4206511028\n",
      "bestIteration = 193\n",
      "\n",
      "22:\tloss: 0.4206511\tbest: 0.4163287 (12)\ttotal: 13.4s\tremaining: 15.2s\n",
      "\n",
      "bestTest = 0.4176058701\n",
      "bestIteration = 186\n",
      "\n",
      "23:\tloss: 0.4176059\tbest: 0.4163287 (12)\ttotal: 14s\tremaining: 14.6s\n",
      "\n",
      "bestTest = 0.4200353451\n",
      "bestIteration = 127\n",
      "\n",
      "24:\tloss: 0.4200353\tbest: 0.4163287 (12)\ttotal: 14.7s\tremaining: 14.1s\n",
      "\n",
      "bestTest = 0.4196807286\n",
      "bestIteration = 193\n",
      "\n",
      "25:\tloss: 0.4196807\tbest: 0.4163287 (12)\ttotal: 15.7s\tremaining: 13.9s\n",
      "\n",
      "bestTest = 0.4175663967\n",
      "bestIteration = 104\n",
      "\n",
      "26:\tloss: 0.4175664\tbest: 0.4163287 (12)\ttotal: 16.3s\tremaining: 13.3s\n",
      "\n",
      "bestTest = 0.4231189451\n",
      "bestIteration = 33\n",
      "\n",
      "27:\tloss: 0.4231189\tbest: 0.4163287 (12)\ttotal: 17.4s\tremaining: 13.1s\n",
      "\n",
      "bestTest = 0.4293232896\n",
      "bestIteration = 199\n",
      "\n",
      "28:\tloss: 0.4293233\tbest: 0.4163287 (12)\ttotal: 18.4s\tremaining: 12.7s\n",
      "\n",
      "bestTest = 0.4198295904\n",
      "bestIteration = 155\n",
      "\n",
      "29:\tloss: 0.4198296\tbest: 0.4163287 (12)\ttotal: 19.2s\tremaining: 12.2s\n",
      "\n",
      "bestTest = 0.4164666209\n",
      "bestIteration = 179\n",
      "\n",
      "30:\tloss: 0.4164666\tbest: 0.4163287 (12)\ttotal: 20s\tremaining: 11.6s\n",
      "\n",
      "bestTest = 0.4222022317\n",
      "bestIteration = 119\n",
      "\n",
      "31:\tloss: 0.4222022\tbest: 0.4163287 (12)\ttotal: 20.8s\tremaining: 11.1s\n",
      "\n",
      "bestTest = 0.4217063018\n",
      "bestIteration = 146\n",
      "\n",
      "32:\tloss: 0.4217063\tbest: 0.4163287 (12)\ttotal: 21.6s\tremaining: 10.5s\n",
      "\n",
      "bestTest = 0.4177675068\n",
      "bestIteration = 133\n",
      "\n",
      "33:\tloss: 0.4177675\tbest: 0.4163287 (12)\ttotal: 22.7s\tremaining: 10s\n",
      "\n",
      "bestTest = 0.4230063684\n",
      "bestIteration = 29\n",
      "\n",
      "34:\tloss: 0.4230064\tbest: 0.4163287 (12)\ttotal: 23.4s\tremaining: 9.38s\n",
      "\n",
      "bestTest = 0.427363113\n",
      "bestIteration = 199\n",
      "\n",
      "35:\tloss: 0.4273631\tbest: 0.4163287 (12)\ttotal: 24.3s\tremaining: 8.78s\n",
      "\n",
      "bestTest = 0.4201538021\n",
      "bestIteration = 194\n",
      "\n",
      "36:\tloss: 0.4201538\tbest: 0.4163287 (12)\ttotal: 25.2s\tremaining: 8.17s\n",
      "\n",
      "bestTest = 0.420895353\n",
      "bestIteration = 124\n",
      "\n",
      "37:\tloss: 0.4208954\tbest: 0.4163287 (12)\ttotal: 26.1s\tremaining: 7.54s\n",
      "\n",
      "bestTest = 0.4220513613\n",
      "bestIteration = 80\n",
      "\n",
      "38:\tloss: 0.4220514\tbest: 0.4163287 (12)\ttotal: 27.1s\tremaining: 6.96s\n",
      "\n",
      "bestTest = 0.4210423189\n",
      "bestIteration = 111\n",
      "\n",
      "39:\tloss: 0.4210423\tbest: 0.4163287 (12)\ttotal: 28.2s\tremaining: 6.35s\n",
      "\n",
      "bestTest = 0.4234517226\n",
      "bestIteration = 85\n",
      "\n",
      "40:\tloss: 0.4234517\tbest: 0.4163287 (12)\ttotal: 29.3s\tremaining: 5.71s\n",
      "\n",
      "bestTest = 0.4235223234\n",
      "bestIteration = 33\n",
      "\n",
      "41:\tloss: 0.4235223\tbest: 0.4163287 (12)\ttotal: 30.1s\tremaining: 5.02s\n",
      "\n",
      "bestTest = 0.4279115567\n",
      "bestIteration = 199\n",
      "\n",
      "42:\tloss: 0.4279116\tbest: 0.4163287 (12)\ttotal: 31.3s\tremaining: 4.37s\n",
      "\n",
      "bestTest = 0.4221977488\n",
      "bestIteration = 147\n",
      "\n",
      "43:\tloss: 0.4221977\tbest: 0.4163287 (12)\ttotal: 32.6s\tremaining: 3.7s\n",
      "\n",
      "bestTest = 0.421670852\n",
      "bestIteration = 56\n",
      "\n",
      "44:\tloss: 0.4216709\tbest: 0.4163287 (12)\ttotal: 33.7s\tremaining: 3s\n",
      "\n",
      "bestTest = 0.4236394869\n",
      "bestIteration = 65\n",
      "\n",
      "45:\tloss: 0.4236395\tbest: 0.4163287 (12)\ttotal: 34.9s\tremaining: 2.27s\n",
      "\n",
      "bestTest = 0.4261959703\n",
      "bestIteration = 75\n",
      "\n",
      "46:\tloss: 0.4261960\tbest: 0.4163287 (12)\ttotal: 36.1s\tremaining: 1.53s\n",
      "\n",
      "bestTest = 0.4212658883\n",
      "bestIteration = 34\n",
      "\n",
      "47:\tloss: 0.4212659\tbest: 0.4163287 (12)\ttotal: 37.3s\tremaining: 777ms\n",
      "\n",
      "bestTest = 0.4298874707\n",
      "bestIteration = 11\n",
      "\n",
      "48:\tloss: 0.4298875\tbest: 0.4163287 (12)\ttotal: 38.7s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Best params {'depth': 3, 'learning_rate': 0.1} obtained at iteration 133 with logloss 0.4095031580039398\n",
      "Dev ROC AUC on best model after grid-search: 0.8300780068597646\n",
      "Test ROC AUC on best model after grid-search: 0.7314290536264293\n",
      "Performing Bayesian search for hyper-parameters optimization, with missing data replaced with an iterative imputer\n",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Argument 'other' has incorrect type (expected _catboost._PoolBase, got type)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument 'other' has incorrect type (expected _catboost._PoolBase, got type)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a1d1b3b189c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0mrstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Re-fitting the model with the best hyper-parameter values found:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m model3 = CatBoostClassifier(iterations=iterations,\n",
      "\u001b[0;32m~/.local/virtualenv/python3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/virtualenv/python3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/virtualenv/python3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/virtualenv/python3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/virtualenv/python3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattach_attachments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemo_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0muse_obj_for_literal_in_memo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCtrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/virtualenv/python3/lib/python3.8/site-packages/hyperopt/utils.py\u001b[0m in \u001b[0;36muse_obj_for_literal_in_memo\u001b[0;34m(expr, obj, lit, memo)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpyll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'other' has incorrect type (expected _catboost._PoolBase, got type)"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import sklearn\n",
    "import itertools\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, space_eval, hp\n",
    "import catboost\n",
    "\n",
    "from util import load_data, cindex\n",
    "\n",
    "seed = 42\n",
    "iterations = 200\n",
    "\n",
    "# Load the NHANES I epidemiology dataset\n",
    "X_dev, X_test, y_dev, y_test = load_data(10)\n",
    "\n",
    "# Convert categorical features from float to int, as that is what CatBoost expects\n",
    "X_dev = X_dev.astype({'Sex': int, 'Race': int})\n",
    "y_dev = y_dev.astype(int)\n",
    "X_test = X_test.astype({'Sex': int, 'Race': int})\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "\n",
    "# Find out how many samples have missing data in one or more variables (columns)\n",
    "def count_samples_with_missing_data(df):\n",
    "    res = sum(df.isnull().any(axis='columns'))\n",
    "    return res\n",
    "\n",
    "\n",
    "dev_missing_count = count_samples_with_missing_data(X_dev)\n",
    "test_missing_count = count_samples_with_missing_data(X_test)\n",
    "\n",
    "print('Dev. set missing data in', dev_missing_count, 'samples out of', len(X_dev))\n",
    "print('Test set missing data in', test_missing_count, 'samples out of', len(X_test))\n",
    "\n",
    "# Split the dev set into training and validation. The latter will be used for hyper-parameters tuning.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Make a dataset after dropping samples with missing data (note, no samples with missing data in test set)\n",
    "X_dev_dropped = X_dev.dropna(axis='rows')\n",
    "y_dev_dropped = y_dev.loc[X_dev_dropped.index]\n",
    "X_train_dropped = X_train.dropna(axis='rows')\n",
    "y_train_dropped = y_train.loc[X_train_dropped.index]\n",
    "X_val_dropped = X_val.dropna(axis='rows')\n",
    "y_val_dropped = y_val.loc[X_val_dropped.index]\n",
    "\n",
    "cat_features = [3, 11]  # Categorical features are race and sex\n",
    "\n",
    "dev_pool_dropped = Pool(data=X_dev_dropped, label=y_dev_dropped, cat_features=cat_features)\n",
    "train_pool_dropped = Pool(data=X_train_dropped, label=y_train_dropped, cat_features=cat_features)\n",
    "val_pool_dropped = Pool(data=X_val_dropped, label=y_val_dropped, cat_features=cat_features)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "# Fit a model on the dataset from where samples with missing data have been dropped\n",
    "print('Fitting a model on the dataset from where samples with missing data have been dropped')\n",
    "model = CatBoostClassifier(iterations=iterations,\n",
    "                           eval_metric='AUC',\n",
    "                           random_state=seed)\n",
    "model.fit(train_pool_dropped, eval_set=val_pool_dropped, verbose=iterations // 10)\n",
    "\n",
    "\n",
    "# Compute the C-index on the train/val/test dataset\n",
    "def print_train_val_test_c_indices(classifier,\n",
    "                                   X_train,\n",
    "                                   y_train,\n",
    "                                   X_val,\n",
    "                                   y_val,\n",
    "                                   X_test,\n",
    "                                   y_test):\n",
    "    y_train_preds = classifier.predict_proba(X_train)[:, 1]\n",
    "    # print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
    "    print(f'Train ROC AUC: {roc_auc_score(y_train, y_train_preds)}')\n",
    "\n",
    "    y_val_preds = classifier.predict_proba(X_val)[:, 1]\n",
    "    # print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_preds)}\")\n",
    "    print(f'Val ROC AUC: {roc_auc_score(y_val, y_val_preds)}')\n",
    "\n",
    "    y_test_preds = classifier.predict_proba(X_test)[:, 1]\n",
    "    # print(f\"Test C-Index: {cindex(y_test.values, y_test_preds)}\")\n",
    "    print(f'Test ROC AUC: {roc_auc_score(y_test, y_test_preds)}')\n",
    "\n",
    "\n",
    "print_train_val_test_c_indices(model,\n",
    "                               X_train_dropped,\n",
    "                               y_train_dropped.values,\n",
    "                               X_val_dropped,\n",
    "                               y_val_dropped.values,\n",
    "                               X_test,\n",
    "                               y_test.values)\n",
    "\n",
    "# Perform grid-search to optimize some of the hyper-parameters\n",
    "print('Performing grid-search for hyper-parameters optimization, without samples with missing data')\n",
    "param_grid = {\n",
    "    'learning_rate': [.01, .05, .06, .07, 0.08, .1, .2],\n",
    "    'depth': [2, 3, 4, 5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "\n",
    "# Determine how many combinations of parameter values are in the grid\n",
    "def compute_n_combinations(grid):\n",
    "    res = 1\n",
    "    for _, value in grid.items():\n",
    "        res *= len(value)\n",
    "    return res\n",
    "\n",
    "\n",
    "n_combos = compute_n_combinations(param_grid)\n",
    "\n",
    "clf = CatBoostClassifier(iterations=iterations,\n",
    "                         eval_metric='AUC:hints=skip_train~false',\n",
    "                         cat_features=cat_features,\n",
    "                         random_state=seed)\n",
    "\n",
    "''' Grid-search is done on the dev. set, as the grid-search takes care of splitting it into training and validation.\n",
    "Note: if `search_by_train_test_split` is set to True, every combination of values of the hyper-parameters is evaluated\n",
    "with a basic training/val. split of the dataset; if set to False, then every combination is evaluated with x-evaluation.\n",
    "Once method grid_search() has found the best combination of hyper-parameters, fits a model with it. The final model \n",
    "can be evaluated with x-evaluation by setting parameter `calc_cv_statistics` to True (default). \n",
    "\n",
    "Note 2: CatBoost grid search chooses the best values for the hyper-parameters based on the loss, not on the eval metric \n",
    "set for the model (AUC).'''\n",
    "grid_search_results = clf.grid_search(param_grid=param_grid,\n",
    "                                      X=dev_pool_dropped,\n",
    "                                      search_by_train_test_split=True,\n",
    "                                      cv=5,\n",
    "                                      calc_cv_statistics=True,\n",
    "                                      partition_random_seed=seed,\n",
    "                                      verbose=True)\n",
    "\n",
    "\n",
    "def print_grid_search_results(results):\n",
    "    best_iter = results['cv_results']['iterations'][\n",
    "        np.argmin(results['cv_results']['test-Logloss-mean'])]\n",
    "    best_loss = np.min(results['cv_results']['test-Logloss-mean'])\n",
    "    print('Best params', results['params'], 'obtained at iteration', best_iter, 'with logloss', best_loss)\n",
    "\n",
    "\n",
    "print_grid_search_results(grid_search_results)\n",
    "\n",
    "\n",
    "# Compute and print C-Indices\n",
    "def print_dev_test_c_indices(classifier, X_dev, y_dev, X_test, y_test):\n",
    "    y_dev_preds = classifier.predict_proba(X_dev)[:, 1]\n",
    "    # print(f\"Dev. C-Index on best model after grid-search: {cindex(y_dev.values, y_dev_preds)}\")\n",
    "    print(f'Dev ROC AUC on best model after grid-search: {roc_auc_score(y_dev.values, y_dev_preds)}')\n",
    "\n",
    "    y_test_preds = clf.predict_proba(X_test)[:, 1]\n",
    "    # print(f\"Test C-Index on best model after grid-search: {cindex(y_test.values, y_test_preds)}\")\n",
    "    print(f'Test ROC AUC on best model after grid-search: {roc_auc_score(y_test.values, y_test_preds)}')\n",
    "\n",
    "\n",
    "print_dev_test_c_indices(clf, X_dev_dropped, y_dev_dropped, X_test, y_test)\n",
    "\n",
    "# Now impute missing values using the mean, instead of dropping samples containing them\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_dev)\n",
    "X_dev_mean_imputed = pd.DataFrame(imputer.transform(X_dev), columns=X_dev.columns)\n",
    "# imputer.transform() above has converted the int columns with categories into float, need to be converted back to int\n",
    "X_dev_mean_imputed = X_dev_mean_imputed.astype({'Sex': int, 'Race': int})\n",
    "dev_pool_mean_imputed = Pool(data=X_dev_mean_imputed, label=y_dev, cat_features=cat_features)\n",
    "\n",
    "''' Note: CatBoost doean't allow to re-tune the hyper-parameters of a model that has been fitted already; need to\n",
    "instantiate a new model '''\n",
    "clf2 = CatBoostClassifier(iterations=iterations,\n",
    "                          eval_metric='Logloss',\n",
    "                          cat_features=cat_features,\n",
    "                          random_state=seed)\n",
    "\n",
    "print('Performing grid-search for hyper-parameters optimization, with missing data replaced with a mean imputer')\n",
    "grid_search_results = clf2.grid_search(param_grid=param_grid,\n",
    "                                       X=dev_pool_mean_imputed,\n",
    "                                       search_by_train_test_split=True,\n",
    "                                       cv=5,\n",
    "                                       partition_random_seed=seed,\n",
    "                                       verbose=True)\n",
    "print_grid_search_results(grid_search_results)\n",
    "\n",
    "print_dev_test_c_indices(clf2, X_dev_mean_imputed, y_dev, X_test, y_test)\n",
    "\n",
    "# Now instead of the mean imputer use an iterative imputer.\n",
    "imputer = IterativeImputer(random_state=seed, sample_posterior=False, max_iter=1, min_value=0)\n",
    "imputer.fit(X_dev)\n",
    "X_dev_iter_imputed = pd.DataFrame(imputer.transform(X_dev), columns=X_dev.columns)\n",
    "# imputer.transform() above has converted the int columns with categories into float, need to be converted back to int\n",
    "X_dev_iter_imputed = X_dev_iter_imputed.astype({'Sex': int, 'Race': int})\n",
    "dev_pool_iter_imputed = Pool(data=X_dev_iter_imputed, label=y_dev, cat_features=cat_features)\n",
    "\n",
    "clf3 = CatBoostClassifier(iterations=iterations,\n",
    "                          eval_metric='Logloss',\n",
    "                          cat_features=cat_features,\n",
    "                          random_state=seed)\n",
    "\n",
    "print('Performing grid-search for hyper-parameters optimization, with missing data replaced with an iterative imputer')\n",
    "grid_search_results = clf3.grid_search(param_grid=param_grid,\n",
    "                                       X=dev_pool_iter_imputed,\n",
    "                                       search_by_train_test_split=True,\n",
    "                                       cv=5,\n",
    "                                       partition_random_seed=seed,\n",
    "                                       verbose=True)\n",
    "print_grid_search_results(grid_search_results)\n",
    "\n",
    "print_dev_test_c_indices(clf, X_dev_iter_imputed, y_dev, X_test, y_test)\n",
    "\n",
    "''' Use the iterative imputer, but use Bayesian optimization for the hyper-parameters, instead of grid search. Here\n",
    "we use the train/val data sets '''\n",
    "print(\n",
    "    'Performing Bayesian search for hyper-parameters optimization, with missing data replaced with an iterative imputer')\n",
    "\n",
    "X_train_iter_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "# imputer.transform() above has converted the int columns with categories into float, need to be converted back to int\n",
    "X_train_iter_imputed = X_train_iter_imputed.astype({'Sex': int, 'Race': int})\n",
    "train_pool_iter_imputed = Pool(data=X_train_iter_imputed, label=y_train, cat_features=cat_features)\n",
    "\n",
    "X_val_iter_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)\n",
    "# imputer.transform() above has converted the int columns with categories into float, need to be converted back to int\n",
    "X_val_iter_imputed = X_val_iter_imputed.astype({'Sex': int, 'Race': int})\n",
    "val_pool_iter_imputed = Pool(data=X_val_iter_imputed, label=y_val, cat_features=cat_features)\n",
    "\n",
    "\n",
    "# The objective function, that hyperopt will minimize\n",
    "def objective(params):\n",
    "    model2 = CatBoostClassifier(iterations=params['iterations'],\n",
    "                                eval_metric='AUC',\n",
    "                                learning_rate=params['learning_rate'],\n",
    "                                depth=params['depth'],\n",
    "                                random_state=params['seed'])\n",
    "    training_res = model2.fit(params['X'], eval_set=params['eval_set'], verbose=False)\n",
    "    auc = training_res.best_score_['validation']['AUC']\n",
    "    return -auc  # The objective function is minimized\n",
    "\n",
    "\n",
    "param_space = {'learning_rate': hp.uniform('learning_rate', .01, .1),\n",
    "               'depth': hp.quniform('depth', 2, 8, 1),\n",
    "               'seed': seed,\n",
    "               'iterations': iterations,\n",
    "               'X': train_pool_iter_imputed,\n",
    "               'eval_set': val_pool_iter_imputed}\n",
    "\n",
    "rstate = np.random.RandomState(seed)\n",
    "best = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=100, rstate=rstate)\n",
    "print('Re-fitting the model with the best hyper-parameter values found:', best)\n",
    "model3 = CatBoostClassifier(iterations=iterations,\n",
    "                            eval_metric='AUC',\n",
    "                            **best,\n",
    "                            random_state=seed)\n",
    "training_res = model3.fit(train_pool_iter_imputed, eval_set=val_pool_iter_imputed, verbose=iterations // 10)\n",
    "\n",
    "print_train_val_test_c_indices(model3,\n",
    "                               X_train_iter_imputed,\n",
    "                               y_train.values,\n",
    "                               X_val_iter_imputed,\n",
    "                               y_val.values,\n",
    "                               X_test,\n",
    "                               y_test.values)\n",
    "\n",
    "''' TODO\n",
    "Check the loss/ROC issue filed on GitHub\n",
    "How does CatBoost deal with missing data (None/NaN)?\n",
    "Unbalanced dataset, try using weights\n",
    "Leverage Tensorboard\n",
    "How to display CatBoost charts outside of notebook? Is it possible?\n",
    "Explore Seaborne\n",
    "Use the whole HANES dataset from CDC, and also try with GPU\n",
    "Try other strategies for imputation based on mean encoding and similar\n",
    "Instead of checking if survival after 10 years, estimate the number of years of survival\n",
    "C-index is the same as the ROC AUC for logistic regression.\n",
    "   see https://www.statisticshowto.com/c-statistic/#:~:text=A%20weighted%20c-index%20is,correctly%20predicting%20a%20negative%20outcome\n",
    "   and also https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4886856/  and https://bit.ly/3dvUh07\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
